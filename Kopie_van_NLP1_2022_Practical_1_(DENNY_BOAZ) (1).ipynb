{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-aRiOgl4nHg"
   },
   "source": [
    "------\n",
    "**You cannot save any changes you make to this file, so please make sure to save it on your Google Colab drive or download it as a .ipynb file.**\n",
    "\n",
    "------\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIZrAUx57vsM"
   },
   "source": [
    "Practical 1: Sentiment Detection in Movie Reviews\n",
    "========================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4kXPMhyngZW"
   },
   "source": [
    "This practical concerns detecting sentiment in movie reviews. This is a typical NLP classification task.\n",
    "In [this file](https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json) (80MB) you will find 1000 positive and 1000 negative **movie reviews**.\n",
    "Each review is a **document** and consists of one or more sentences.\n",
    "\n",
    "To prepare yourself for this practical, you should\n",
    "have a look at a few of these texts to understand the difficulties of\n",
    "the task: how might one go about classifying the texts? You will write\n",
    "code that decides whether a movie review conveys positive or\n",
    "negative sentiment.\n",
    "\n",
    "Please make sure you have read the following paper:\n",
    "\n",
    ">   Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan\n",
    "(2002). \n",
    "[Thumbs up? Sentiment Classification using Machine Learning\n",
    "Techniques](https://dl.acm.org/citation.cfm?id=1118704). EMNLP.\n",
    "\n",
    "Bo Pang et al. introduced the movie review sentiment\n",
    "classification task, and the above paper was one of the first papers on\n",
    "the topic. The first version of your sentiment classifier will do\n",
    "something similar to Pang et al.'s system. If you have questions about it,\n",
    "you should resolve you doubts as soon as possible with your TA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb7errgRASzZ"
   },
   "source": [
    "**Advice**\n",
    "\n",
    "Please read through the entire practical and familiarise\n",
    "yourself with all requirements before you start coding or otherwise\n",
    "solving the tasks. Writing clean and concise code can make the difference\n",
    "between solving the assignment in a matter of hours, and taking days to\n",
    "run all experiments.\n",
    "\n",
    "## Environment\n",
    "\n",
    "All code should be written in **Python 3**. \n",
    "This is the default in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaZnxptMJiD7",
    "outputId": "ab9c11ae-c3f9-4a69-a4f6-6b97c7dd05c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.15\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYZyIF7lJnGn"
   },
   "source": [
    "If you want to run code on your own computer, then download this notebook through `File -> Download .ipynb`.\n",
    "The easiest way to\n",
    "install Python is through downloading\n",
    "[Anaconda](https://www.anaconda.com/download). \n",
    "After installation, you can start the notebook by typing `jupyter notebook filename.ipynb`.\n",
    "You can also use an IDE\n",
    "such as [PyCharm](https://www.jetbrains.com/pycharm/download/) to make\n",
    "coding and debugging easier. It is good practice to create a [virtual\n",
    "environment](https://docs.python.org/3/tutorial/venv.html) for this\n",
    "project, so that any Python packages don’t interfere with other\n",
    "projects. \n",
    " \n",
    "\n",
    "**Learning Python 3**\n",
    "\n",
    "If you are new to Python 3, you may want to check out a few of these resources:\n",
    "- https://learnxinyminutes.com/docs/python3/\n",
    "- https://www.learnpython.org/\n",
    "- https://docs.python.org/3/tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hok-BFu9lGoK"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import sklearn as sk\n",
    "from google.colab import drive\n",
    "import pickle\n",
    "import json\n",
    "from collections import Counter\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXWyGHwE-ieQ"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "**Download the sentiment lexicon and the movie reviews dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lm-rakqtlMOT",
    "outputId": "4f4ad938-bce3-4f32-fb45-324f38c9ee7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-16 14:14:13--  https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 662577 (647K) [text/plain]\n",
      "Saving to: ‘sent_lexicon’\n",
      "\n",
      "\r",
      "sent_lexicon          0%[                    ]       0  --.-KB/s               \r",
      "sent_lexicon        100%[===================>] 647.05K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2022-11-16 14:14:13 (14.8 MB/s) - ‘sent_lexicon’ saved [662577/662577]\n",
      "\n",
      "--2022-11-16 14:14:13--  https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 83503869 (80M) [text/plain]\n",
      "Saving to: ‘reviews.json’\n",
      "\n",
      "reviews.json        100%[===================>]  79.63M   223MB/s    in 0.4s    \n",
      "\n",
      "2022-11-16 14:14:13 (223 MB/s) - ‘reviews.json’ saved [83503869/83503869]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download sentiment lexicon\n",
    "!wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n",
    "# download review data\n",
    "!wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkPwuHp5LSuQ"
   },
   "source": [
    "**Load the movie reviews.**\n",
    "\n",
    "Each word in a review comes with its part-of-speech tag. For documentation on POS-tags, see https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "careEKj-mRpl",
    "outputId": "f035e210-8147-4f52-84c9-dba660e1bbac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: 2000 \n",
      "\n",
      "0 NEG 29\n",
      "Two/CD teen/JJ couples/NNS go/VBP to/TO a/DT church/NN party/NN ,/, drink/NN and/CC then/RB drive/NN ./.\n",
      "1 NEG 11\n",
      "Damn/JJ that/IN Y2K/CD bug/NN ./.\n",
      "2 NEG 24\n",
      "It/PRP is/VBZ movies/NNS like/IN these/DT that/WDT make/VBP a/DT jaded/JJ movie/NN viewer/NN thankful/JJ for/IN the/DT invention/NN of/IN the/DT Timex/NNP IndiGlo/NNP watch/NN ./.\n",
      "3 NEG 19\n",
      "QUEST/NN FOR/IN CAMELOT/NNP ``/`` Quest/NNP for/IN Camelot/NNP ''/'' is/VBZ Warner/NNP Bros./NNP '/POS first/JJ feature-length/JJ ,/, fully-animated/JJ attempt/NN to/TO steal/VB clout/NN from/IN Disney/NNP 's/POS cartoon/NN empire/NN ,/, but/CC the/DT mouse/NN has/VBZ no/DT reason/NN to/TO be/VB worried/VBN ./.\n",
      "4 NEG 38\n",
      "Synopsis/NNPS :/: A/DT mentally/RB unstable/JJ man/NN undergoing/VBG psychotherapy/NN saves/VBZ a/DT boy/NN from/IN a/DT potentially/RB fatal/JJ accident/NN and/CC then/RB falls/VBZ in/IN love/NN with/IN the/DT boy/NN 's/POS mother/NN ,/, a/DT fledgling/NN restauranteur/NN ./.\n",
      "\n",
      "Number of word types: 47743\n",
      "Number of word tokens: 1512359\n",
      "\n",
      "Most common tokens:\n",
      "         , :    77842\n",
      "       the :    75948\n",
      "         . :    59027\n",
      "         a :    37583\n",
      "       and :    35235\n",
      "        of :    33864\n",
      "        to :    31601\n",
      "        is :    25972\n",
      "        in :    21563\n",
      "        's :    18043\n",
      "        it :    15904\n",
      "      that :    15820\n",
      "     -rrb- :    11768\n",
      "     -lrb- :    11670\n",
      "        as :    11312\n",
      "      with :    10739\n",
      "       for :     9816\n",
      "       his :     9542\n",
      "      this :     9497\n",
      "      film :     9404\n"
     ]
    }
   ],
   "source": [
    "# file structure:\n",
    "# [\n",
    "#  {\"cv\": integer, \"sentiment\": str, \"content\": list} \n",
    "#  {\"cv\": integer, \"sentiment\": str, \"content\": list} \n",
    "#   ..\n",
    "# ]\n",
    "# where `content` is a list of sentences, \n",
    "# with a sentence being a list of (token, pos_tag) pairs.\n",
    "\n",
    "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  reviews = json.load(f)\n",
    "  \n",
    "print(\"Total number of reviews:\", len(reviews), '\\n')\n",
    "\n",
    "def print_sentence_with_pos(s):\n",
    "  print(\" \".join(\"%s/%s\" % (token, pos_tag) for token, pos_tag in s))\n",
    "\n",
    "for i, r in enumerate(reviews):\n",
    "  print(r[\"cv\"], r[\"sentiment\"], len(r[\"content\"]))  # cv, sentiment, num sents\n",
    "  print_sentence_with_pos(r[\"content\"][0])\n",
    "  if i == 4: \n",
    "    break\n",
    "    \n",
    "c = Counter()\n",
    "for review in reviews:\n",
    "  for sentence in review[\"content\"]:\n",
    "    for token, pos_tag in sentence:\n",
    "      c[token.lower()] += 1\n",
    "      \n",
    "print(\"\\nNumber of word types:\", len(c))\n",
    "print(\"Number of word tokens:\", sum(c.values()))\n",
    "\n",
    "print(\"\\nMost common tokens:\")\n",
    "for token, count in c.most_common(20):\n",
    "  print(\"%10s : %8d\" % (token, count))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "68-SjOwHIAkv"
   },
   "outputs": [],
   "source": [
    "# Retrieve the words from a given part of the reviews\n",
    "\n",
    "def retrieve_words(data):\n",
    "  words = []\n",
    "  for rev in data:\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        words.append(word[0].lower())\n",
    "\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0uWH1dZzIBnf"
   },
   "outputs": [],
   "source": [
    "# Retrieve all unique words for a given part of the reviews\n",
    "\n",
    "def retrieve_unique_words(train):\n",
    "  unique_words = []\n",
    "  for rev in train:\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        if word[0].lower() not in unique_words:\n",
    "          unique_words.append(word[0].lower())\n",
    "  return unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6PWaEoh8B34"
   },
   "source": [
    "#(1) Lexicon-based approach (3.5pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsTSMb6ma4E8"
   },
   "source": [
    "A traditional approach to classify documents according to their sentiment is the lexicon-based approach. To implement this approach, you need a **sentiment lexicon**, i.e., a list of words annotated with a sentiment label (e.g., positive and negative, or a score from 0 to 5).\n",
    "\n",
    "In this practical, you will use the sentiment\n",
    "lexicon released by Wilson et al. (2005).\n",
    "\n",
    "> Theresa Wilson, Janyce Wiebe, and Paul Hoffmann\n",
    "(2005). [Recognizing Contextual Polarity in Phrase-Level Sentiment\n",
    "Analysis](http://www.aclweb.org/anthology/H/H05/H05-1044.pdf). HLT-EMNLP.\n",
    "\n",
    "Pay attention to all the information available in the sentiment lexicon. The field *word1* contains the lemma, *priorpolarity* contains the sentiment label (positive, negative, both, or neutral), *type* gives you the magnitude of the word's sentiment (strong or weak), and *pos1* gives you the part-of-speech tag of the lemma. Some lemmas can have multiple part-of-speech tags and thus multiple entries in the lexicon. The path of the lexicon file is `\"sent_lexicon\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ogq0Eq2hQglh",
    "outputId": "721526d0-eace-4269-b001-712198d54ccd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type=weaksubj len=1 word1=abandoned pos1=adj stemmed1=n priorpolarity=negative\n",
      "type=weaksubj len=1 word1=abandonment pos1=noun stemmed1=n priorpolarity=negative\n",
      "type=weaksubj len=1 word1=abandon pos1=verb stemmed1=y priorpolarity=negative\n",
      "type=strongsubj len=1 word1=abase pos1=verb stemmed1=y priorpolarity=negative\n",
      "type=strongsubj len=1 word1=abasement pos1=anypos stemmed1=y priorpolarity=negative\n"
     ]
    }
   ],
   "source": [
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  line_cnt = 0\n",
    "  for line in f:\n",
    "    print(line.strip())\n",
    "    line_cnt += 1\n",
    "    if line_cnt > 4:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mml4nOtIUBhn"
   },
   "source": [
    "Lexica such as this can be used to solve\n",
    "the classification task without using Machine Learning. For example, one might look up every word $w_1 ... w_n$ in a document, and compute a **binary score**\n",
    "$S_{binary}$ by counting how many words have a positive or a\n",
    "negative label in the sentiment lexicon $SLex$.\n",
    "\n",
    "$$S_{binary}(w_1 w_2 ... w_n) = \\sum_{i = 1}^{n}\\text{sign}(SLex\\big[w_i\\big])$$\n",
    "\n",
    "where $\\text{sign}(SLex\\big[w_i\\big])$ refers to the polarity of $w_i$.\n",
    "\n",
    "**Threshold.** On average, there are more positive than negative words per review (~7.13 more positive than negative per review) to take this bias into account you should use a threshold of **8** (roughly the bias itself) to make it harder to classify as positive.\n",
    "\n",
    "$$\n",
    "\\text{classify}(S_{binary}(w_1 w_2 ... w_n)) = \\bigg\\{\\begin{array}{ll}\n",
    "        \\text{positive} & \\text{if } S_{binary}(w_1w_2...w_n) > threshold\\\\\n",
    "        \\text{negative} & \\text{otherwise}\n",
    "        \\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOFnMvbeeZrc"
   },
   "source": [
    "#### (Q1.1) Implement this approach and report its classification accuracy. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ED2aTEYutW1-"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import wordlist\n",
    "\n",
    "# Create a list of all the words in the file 'sent_lexicon'\n",
    "words = []\n",
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  for line in f:\n",
    "    start = line.find('word1')\n",
    "    stop = line.find(\" \",start)\n",
    "    words.append(line[start+ 6:stop])\n",
    "\n",
    "# Create a list of the polarity of each word in the file 'sent_lexicon'\n",
    "priorpolarity = []\n",
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  for line in f:\n",
    "    start = line.find('priorpolarity')\n",
    "    stop = line.find(\" \",start)\n",
    "    priorpolarity.append(line[start+ 14:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hSdHuVgYj6t6"
   },
   "outputs": [],
   "source": [
    "def classify_rev(reviews, priorpolarity, mag=None, avg_doc_length=None):\n",
    "  result = []\n",
    "\n",
    "  # Classify each review based on the sentiment of the words in the review\n",
    "  for rev in reviews:\n",
    "    pos_words = 0\n",
    "    rev_pos = ''\n",
    "    doc_length = 0\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        if word[0].lower() in words:\n",
    "          doc_length += 1\n",
    "\n",
    "          # Find the polarity of the word\n",
    "          index_word = words.index(word[0].lower())\n",
    "          posneg = priorpolarity[index_word]\n",
    "\n",
    "          # Change amount of positive words based on sentiment of evaluated word\n",
    "          if mag:\n",
    "            # Use the magnitude of the sentiment of each word\n",
    "            strongweak = mag[index_word]\n",
    "            if strongweak == 'weaksubj':\n",
    "              if posneg == 'positive':\n",
    "                pos_words += 1\n",
    "              if posneg == 'negative':\n",
    "                pos_words -= 1\n",
    "            if strongweak == 'strongsubj':\n",
    "              if posneg == 'positive':\n",
    "                pos_words += 2\n",
    "              if posneg == 'negative':\n",
    "                pos_words -= 2\n",
    "          else:\n",
    "            if posneg == 'positive':\n",
    "              pos_words += 1\n",
    "            if posneg == 'negative':\n",
    "              pos_words -= 1\n",
    "\n",
    "    # Set a threshold for the amount of positive words\n",
    "    if avg_doc_length:\n",
    "      # Adjust the threshold based on the document length\n",
    "      threshold = (doc_length / avg_doc_length) * 7.13\n",
    "    elif mag:\n",
    "      threshold = 10\n",
    "    else:\n",
    "      threshold = 7\n",
    "    \n",
    "    if pos_words > threshold:\n",
    "      rev_pos = 'POS'\n",
    "    else:\n",
    "      rev_pos = 'NEG'\n",
    "\n",
    "    if rev_pos == rev['sentiment']:\n",
    "      result.append(1)\n",
    "    else:\n",
    "      result.append(0)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iy528EUTphz5",
    "outputId": "b61fb962-7dbb-4226-a15c-0ee5f0ca58e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "# token_results should be a list of binary indicators; for example [1, 0, 1, ...] \n",
    "# where 1 indicates a correct classification and 0 an incorrect classification.\n",
    "result = classify_rev(reviews,priorpolarity)\n",
    "\n",
    "token_accuracy = sum(result) / len(result)\n",
    "print(\"Accuracy: %0.2f\" % token_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twox0s_3eS0V"
   },
   "source": [
    "As the sentiment lexicon also has information about the **magnitude** of\n",
    "sentiment (e.g., *“excellent\"* has the same sentiment _polarity_ as *“good\"* but it has a higher magnitude), we can take a more fine-grained approach by adding up all\n",
    "sentiment scores, and deciding the polarity of the movie review using\n",
    "the sign of the weighted score $S_{weighted}$.\n",
    "\n",
    "$$S_{weighted}(w_1w_2...w_n) = \\sum_{i = 1}^{n}SLex\\big[w_i\\big]$$\n",
    "\n",
    "\n",
    "Make sure you define an appropriate threshold for this approach.\n",
    "\n",
    "#### (Q1.2) Now incorporate magnitude information and report the classification accuracy. Don't forget to use the threshold. (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qG3hUDnPtkhS"
   },
   "outputs": [],
   "source": [
    "# Find the magnitude of the sentiment of each word in the lexicon.\n",
    "mag = []\n",
    "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "  for line in f:\n",
    "    start = line.find('type=')\n",
    "    stop = line.find(\" \",start)\n",
    "    mag.append(line[start+ 5:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFQ0QHWLvR15",
    "outputId": "c7fc1579-b8a1-4be5-eef2-378e802a5e34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.517\n"
     ]
    }
   ],
   "source": [
    "# Find the average difference of sentiment score based on the word polarities\n",
    "\n",
    "score_dif = []\n",
    "for rev in reviews:\n",
    "  pos_score, neg_score = 0, 0\n",
    "  for sentence in rev['content']:\n",
    "    for word in sentence:\n",
    "      if word[0].lower() in words:\n",
    "          # Find the polarity of the word\n",
    "          index_word = words.index(word[0].lower())\n",
    "          posneg = priorpolarity[index_word]\n",
    "          strongweak = mag[index_word]\n",
    "          if strongweak == 'weaksubj':\n",
    "            if posneg == 'positive':\n",
    "              pos_score += 1\n",
    "            if posneg == 'negative':\n",
    "              neg_score += 1\n",
    "          if strongweak == 'strongsubj':\n",
    "            if posneg == 'positive':\n",
    "              pos_score += 2\n",
    "            if posneg == 'negative':\n",
    "              neg_score += 2\n",
    "  score_dif.append(pos_score - neg_score)\n",
    "\n",
    "avg_score = np.mean(score_dif)\n",
    "\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vVk7CvDpyka",
    "outputId": "6aab89e7-b912-45ed-8596-4271aa003ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.684\n",
      "Accuracy with the magnitude of the sentiment: 0.688\n"
     ]
    }
   ],
   "source": [
    "result2 = classify_rev(reviews, priorpolarity, mag=mag)\n",
    "\n",
    "magnitude_accuracy = sum(result2) / len(result2)\n",
    "print(\"Accuracy: %0.3f\" % token_accuracy)\n",
    "print(\"Accuracy with the magnitude of the sentiment: %0.3f\" % magnitude_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9SHoGPfsAHV"
   },
   "source": [
    "#### (Q.1.3) Make a barplot of the two results (0.5pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "8LgBcYcXsEk3",
    "outputId": "4000e70b-dbeb-48ff-d34f-e885597a7805"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "accuracies = ['sentiment without magnitude', 'sentiment with magnitude']\n",
    "values= [token_accuracy, magnitude_accuracy]\n",
    "bar_colors = ['blue', 'red']\n",
    "ax.bar(accuracies, values, color=bar_colors)\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracies for sentiment classification of movie reviews')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNhS8OCVxMHd"
   },
   "source": [
    "#### (Q1.4) A better threshold (1pt)\n",
    "Above we have defined a threshold to account for an inherent bias in the dataset: there are more positive than negative words per review.\n",
    "However, that threshold does not take into account *document length*. Explain why this is a problem and implement an alternative way to compute the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo7gk1I-omLI"
   },
   "source": [
    "The defined threshold is a minimum amount of 7 positive words. The difference in the amount of positive and negative words depends on the document length. For a document with an average length there will be on average 7 more positive words. If the document is longer than average the difference between the amount of positive words and negative words will on average be larger. This means that the treshold must be higher for a large document, and lower for a small document. Using a threshold of 7 more positive words can be a problem, since a very large document can contain only the minimum difference between the amount of positive and negative words to exceed the threshold, while in this large documents there should on average be more positive words to be classified as positive according to expected difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dwt0B8h8aKjr",
    "outputId": "588ab3ee-8562-4a7e-a1e8-8efbdad888a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.0305\n"
     ]
    }
   ],
   "source": [
    "doc_length_list = []\n",
    "\n",
    "# Find the length of each review\n",
    "for rev in reviews:\n",
    "  doc_length = 0\n",
    "  rev_pos = ''\n",
    "  for sentence in rev['content']:\n",
    "    for word in sentence:\n",
    "      if word[0].lower() in words:\n",
    "        doc_length += 1\n",
    "  doc_length_list.append(doc_length)\n",
    "\n",
    "# Calculate the average length of the reviews\n",
    "avg_doc_length = np.mean(doc_length_list)\n",
    "print(avg_doc_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZ7ek86wDpgQ",
    "outputId": "4f1a71c3-94a8-40fd-93ea-b4f659fedac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.669\n"
     ]
    }
   ],
   "source": [
    "result3 = classify_rev(reviews, priorpolarity, mag=mag, \n",
    "                       avg_doc_length=avg_doc_length)\n",
    "\n",
    "accuracy = sum(result3) / len(result3)\n",
    "print(\"Accuracy: %0.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LibV4nR89BXb"
   },
   "source": [
    "# (2) Naive Bayes (9.5pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnF9adQnuwia"
   },
   "source": [
    "\n",
    "Your second task is to program a simple Machine Learning approach that operates\n",
    "on a simple Bag-of-Words (BoW) representation of the text data, as\n",
    "described by Pang et al. (2002). In this approach, the only features we\n",
    "will consider are the words in the text themselves, without bringing in\n",
    "external sources of information. The BoW model is a popular way of\n",
    "representing texts as vectors, making it\n",
    "easy to apply classical Machine Learning algorithms on NLP tasks.\n",
    "However, the BoW representation is also very crude, since it discards\n",
    "all information related to word order and grammatical structure in the\n",
    "original text—as the name suggests.\n",
    "\n",
    "## Writing your own classifier (4pts)\n",
    "\n",
    "Write your own code to implement the Naive Bayes (NB) classifier. As\n",
    "a reminder, the Naive Bayes classifier works according to the following\n",
    "equation:\n",
    "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} P(c|\\bar{f}) = \\operatorname*{arg\\,max}_{c \\in C} P(c)\\prod^n_{i=1} P(f_i|c)$$\n",
    "where $C = \\{ \\text{POS}, \\text{NEG} \\}$ is the set of possible classes,\n",
    "$\\hat{c} \\in C$ is the most probable class, and $\\bar{f}$ is the feature\n",
    "vector. Remember that we use the log of these probabilities when making\n",
    "a prediction:\n",
    "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} \\Big\\{\\log P(c) + \\sum^n_{i=1} \\log P(f_i|c)\\Big\\}$$\n",
    "\n",
    "You can find more details about Naive Bayes in [Jurafsky &\n",
    "Martin](https://web.stanford.edu/~jurafsky/slp3/). You can also look at\n",
    "this helpful\n",
    "[pseudo-code](https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html).\n",
    "\n",
    "*Note: this section and the next aim to put you in a position to replicate\n",
    "    Pang et al.'s Naive Bayes results. However, your numerical results\n",
    "    will differ from theirs, as they used different data.*\n",
    "\n",
    "**You must write the Naive Bayes training and prediction code from\n",
    "scratch.** You will not be given credit for using off-the-shelf Machine\n",
    "Learning libraries.\n",
    "\n",
    "The data contains the text of the reviews, where each document consists\n",
    "of the sentences in the review, the sentiment of the review and an index\n",
    "(cv) that you will later use for cross-validation. The\n",
    "text has already been tokenised and POS-tagged for you. Your algorithm\n",
    "should read in the text, **lowercase it**, store the words and their\n",
    "frequencies in an appropriate data structure that allows for easy\n",
    "computation of the probabilities used in the Naive Bayes algorithm, and\n",
    "then make predictions for new instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEpyQSBSkb33"
   },
   "source": [
    "#### (Q2.1) Unseen words (1pt)\n",
    "The presence of words in the test dataset that\n",
    "have not been seen during training can cause probabilities in the Naive Bayes classifier to equal $0$.\n",
    "These can be words which are unseen in both positive and negative training reviews (case 1), but also words which are seen in reviews _of only one sentiment class_ in the training dataset (case 2). In both cases, **you should skip these words for both classes**.  What would be the problem instead with skipping words only for one class in case 2? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BanFiYYnoxDW"
   },
   "source": [
    "If a word is skipped for one of the classes the overall probability does not change based on this word. Especially when a word is not seen in the entire class the probability should get lower when that word is observed. When skipping it for one class the probability does not change for that class while the probability of the other class gets smaller, because the probability of that word is used to calculate the overall probability for that class. This is a problem since the chance of classifying to the class where the words is not observed gets bigger than the chance of classifying to the other class in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsZRhaI3WvzC"
   },
   "source": [
    "#### (Q2.2) Train your classifier on (positive and negative) reviews with cv-value 000-899, and test it on the remaining (positive and negative) reviews cv900–cv999.  Report results using classification accuracy as your evaluation metric. Your  features are the word vocabulary. The value of a feature is the count of that feature (word) in the document. (2pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7zaJYGFvIJ3"
   },
   "outputs": [],
   "source": [
    "# TRAINING DATA\n",
    "train_data1 = reviews[:900]\n",
    "test_data1 = reviews[900:1000]\n",
    "train_data2 = reviews[1000:1900]\n",
    "test_data2 = reviews[1900:]\n",
    "train_data = train_data1 + train_data2\n",
    "test_data = test_data1 + test_data2\n",
    "\n",
    "# Find all the words in the positive training data\n",
    "test_x_neg = [r['content'] for r in train_data2]\n",
    "train_word_pos = []\n",
    "for rev in test_x_neg:\n",
    "  for sentence in rev:\n",
    "    for word in sentence:\n",
    "        train_word_pos.append(word[0].lower())\n",
    "\n",
    "# Find all the words in the negative training data\n",
    "test_x_pos = [r['content'] for r in train_data1]\n",
    "train_word_neg = []\n",
    "for rev in test_x_pos:\n",
    "  for sentence in rev:\n",
    "    for word in sentence:\n",
    "        train_word_neg.append(word[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zX-Ykfp8Buol",
    "outputId": "534bb71e-0569-4977-dcb2-1424b8190db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "count_pos = Counter(train_word_pos)\n",
    "count_neg = Counter(train_word_neg)\n",
    "total_pos = sum(count_pos.values())\n",
    "total_neg = sum(count_neg.values())\n",
    "\n",
    "prob =[]\n",
    "for rev in test_data:\n",
    "  pr_pos = 0\n",
    "  pr_neg = 0\n",
    "  for sentence in rev['content']:\n",
    "    for word in sentence:\n",
    "      if word[0].lower() in count_pos.keys() and word[0].lower() in count_neg.keys():\n",
    "        pr_pos += np.log(count_pos[word[0].lower()] / total_pos)\n",
    "        pr_neg += np.log(count_neg[word[0].lower()] / total_neg)\n",
    "  prob.append(np.argmax([pr_neg,pr_pos]))\n",
    "\n",
    "test_y = [label['sentiment'] for label in test_data]\n",
    "test_y_new = []\n",
    "for i in test_y:\n",
    "  if i == 'NEG':\n",
    "    test_y_new.append(0)\n",
    "  if i == 'POS':\n",
    "    test_y_new.append(1)\n",
    "sum(test_y_new)\n",
    "\n",
    "result = []\n",
    "for i in range(len(test_y_new)):\n",
    "  if test_y_new[i] == prob[i]:\n",
    "    result.append(1)\n",
    "  else:\n",
    "    result.append(0)\n",
    "\n",
    "result =sum(result) / len(result)\n",
    "print(\"Accuracy: %0.3f\" % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0INK-PBoM6CB"
   },
   "source": [
    "#### (Q2.3) Would you consider accuracy to also be a good way to evaluate your classifier in a situation where 90% of your data instances are of positive movie reviews? (1pt)\n",
    "\n",
    "Simulate this scenario by keeping the positive reviews\n",
    "data unchanged, but only using negative reviews cv000–cv089 for\n",
    "training, and cv900–cv909 for testing. Calculate the classification\n",
    "accuracy, and explain what changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFbcsYlipBAw"
   },
   "source": [
    "Accuracy is not good to evaulate the classification in a situation where 90% of the data instances are of positive movie reviews. If there is a strong imbalance in the amount of each class the accuracy gives a distorted result. For example, in the case that all the reviews (100%) are classified as positive while 90% is actually positive, the accuracy will be 90%. The accuracy is high while the classification of negative reviews is not working at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWDkt5ZrrFGp"
   },
   "outputs": [],
   "source": [
    "train_data1 = reviews[:90]\n",
    "test_data1 = reviews[900:910]\n",
    "train_data2 = reviews[1000:1900]\n",
    "test_data2 = reviews[1900:]\n",
    "train_data = train_data1 + train_data2\n",
    "test_data = test_data1 + test_data2\n",
    "\n",
    "# Find all the words in the positive training data\n",
    "test_x = [r['content'] for r in train_data2]\n",
    "train_word_pos = []\n",
    "for rev in test_x:\n",
    "  for sentence in rev:\n",
    "    for word in sentence:\n",
    "        train_word_pos.append(word[0].lower())\n",
    "\n",
    "# Find all the words in the positive training data\n",
    "test_x = [r['content'] for r in train_data1]\n",
    "train_word_neg = []\n",
    "for rev in test_x:\n",
    "  for sentence in rev:\n",
    "    for word in sentence:\n",
    "        train_word_neg.append(word[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOZirJRatlao",
    "outputId": "980343f6-43e6-456c-a0d4-ba3fa47a7aab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.909\n"
     ]
    }
   ],
   "source": [
    "count_pos = Counter(train_word_pos)\n",
    "count_neg = Counter(train_word_neg)\n",
    "total_pos = sum(count_pos.values())\n",
    "total_neg = sum(count_neg.values())\n",
    "\n",
    "prob =[]\n",
    "for rev in test_data:\n",
    "  #print(rev['sentiment'])\n",
    "  pr_pos = 0\n",
    "  pr_neg = 0\n",
    "  for sentence in rev['content']:\n",
    "    for word in sentence:\n",
    "      if word[0].lower() in count_pos.keys() and word[0].lower() in count_neg.keys():\n",
    "        pr_pos += np.log(count_pos[word[0].lower()] / total_pos) + np.log(0.9)\n",
    "        pr_neg += np.log(count_neg[word[0].lower()] / total_neg) + np.log(0.1)\n",
    "  prob.append(np.argmax([pr_neg,pr_pos]))\n",
    "\n",
    "test_y = [label['sentiment'] for label in test_data]\n",
    "test_y_new = []\n",
    "for i in test_y:\n",
    "  if i == 'NEG':\n",
    "    test_y_new.append(0)\n",
    "  if i == 'POS':\n",
    "    test_y_new.append(1)\n",
    "sum(test_y_new)\n",
    "\n",
    "result = []\n",
    "for i in range(len(test_y_new)):\n",
    "  if test_y_new[i] == prob[i]:\n",
    "    result.append(1)\n",
    "  else:\n",
    "    result.append(0)\n",
    "\n",
    "result =sum(result) / len(result)\n",
    "print(\"Accuracy: %0.3f\" % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wJzcHX3WUDm"
   },
   "source": [
    "## Smoothing (1pt)\n",
    "\n",
    "As mentioned above, the presence of words in the test dataset that\n",
    "have not been seen during training can cause probabilities in the Naive\n",
    "Bayes classifier to be $0$, thus making that particular test instance\n",
    "undecidable. The standard way to mitigate this effect (as well as to\n",
    "give more clout to rare words) is to use smoothing, in which the\n",
    "probability fraction\n",
    "$$\\frac{\\text{count}(w_i, c)}{\\sum\\limits_{w\\in V} \\text{count}(w, c)}$$ for a word\n",
    "$w_i$ becomes\n",
    "$$\\frac{\\text{count}(w_i, c) + \\text{smoothing}(w_i)}{\\sum\\limits_{w\\in V} \\text{count}(w, c) + \\sum\\limits_{w \\in V} \\text{smoothing}(w)}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBNIcbwUWphC"
   },
   "source": [
    "#### (Q2.4) Implement Laplace feature smoothing (1pt)\n",
    "Implement Laplace smoothing, i.e., smoothing with a constant value ($smoothing(w) = \\kappa, \\forall w \\in V$), in your Naive\n",
    "Bayes classifier’s code, and report the impact on performance. \n",
    "Use $\\kappa = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g03yflCc9kpW"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# TRAINING DATA\n",
    "train_data1 = reviews[:900]\n",
    "test_data1 = reviews[900:1000]\n",
    "train_data2 = reviews[1000:1900]\n",
    "test_data2 = reviews[1900:]\n",
    "train_data = train_data1 + train_data2\n",
    "test_data = test_data1 + test_data2\n",
    "\n",
    "# TRAIN DATA POSITIVE\n",
    "test_y = [label['sentiment'] for label in train_data2]\n",
    "test_x = [r['content'] for r in train_data2]\n",
    "\n",
    "# COUNT WORDS TRAINDATA POSITIVE\n",
    "train_word_pos = []\n",
    "for rev in test_x:\n",
    "  for sentence in rev:\n",
    "    for word in sentence:\n",
    "        train_word_pos.append(word[0].lower())\n",
    "\n",
    "# TRAIN DATA NEGATIVE\n",
    "test_y = [label['sentiment'] for label in train_data1]\n",
    "test_x = [r['content'] for r in train_data1]\n",
    "\n",
    "# # COUNT WORDS TRAINDATA negative\n",
    "train_word_neg = []\n",
    "for rev in test_x:\n",
    "  for sentence in rev:\n",
    "    for word in sentence:\n",
    "        train_word_neg.append(word[0].lower())\n",
    "\n",
    "count_pos = Counter(train_word_pos)\n",
    "count_neg = Counter(train_word_neg)\n",
    "total_pos = sum(count_pos.values())\n",
    "total_neg = sum(count_neg.values())\n",
    "# TRAINING WORDS \n",
    "train_y = [label['sentiment'] for label in train_data]\n",
    "train_x = [r['content'] for r in train_data]\n",
    "train_words = []\n",
    "for rev in train_x:\n",
    "  for sentence in rev:\n",
    "    for word in sentence:\n",
    "      if word[0].lower() not in train_words:\n",
    "        train_words.append(word[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSSu8G1VyThZ",
    "outputId": "87430ac4-9916-421b-c336-3210f0f5d6d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]\n",
      "Accuracy: 0.8250\n"
     ]
    }
   ],
   "source": [
    "prob = []\n",
    "for rev in test_data:\n",
    "  pr_pos = 0\n",
    "  pr_neg = 0\n",
    "  for sentence in rev['content']:\n",
    "    for word in sentence:\n",
    "        pr_pos += np.log((count_pos[word[0].lower()] + 1) / (total_pos + len(train_words)))\n",
    "        pr_neg += np.log((count_neg[word[0].lower()] + 1) / (total_neg + len(train_words)))\n",
    "  prob.append(np.argmax([pr_neg,pr_pos]))\n",
    "\n",
    "print(prob)\n",
    "test_y = [label['sentiment'] for label in test_data]\n",
    "test_y_new = []\n",
    "for i in test_y:\n",
    "  if i == 'NEG':\n",
    "    test_y_new.append(0)\n",
    "  if i == 'POS':\n",
    "    test_y_new.append(1)\n",
    "sum(test_y_new)\n",
    "\n",
    "result = []\n",
    "for i in range(len(test_y_new)):\n",
    "  if test_y_new[i] == prob[i]:\n",
    "    result.append(1)\n",
    "  else:\n",
    "    result.append(0)\n",
    "\n",
    "result =sum(result) / len(result)\n",
    "print(\"Accuracy: %0.4f\" % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiGcgwba87D5"
   },
   "source": [
    "## Cross-Validation (1.5pts)\n",
    "\n",
    "A serious danger in using Machine Learning on small datasets, with many\n",
    "iterations of slightly different versions of the algorithms, is ending up with Type III errors, also called the “testing hypotheses\n",
    "suggested by the data” errors. This type of error occurs when we make\n",
    "repeated improvements to our classifiers by playing with features and\n",
    "their processing, but we don’t get a fresh, never-before seen test\n",
    "dataset every time. Thus, we risk developing a classifier that gets better\n",
    "and better on our data, but only gets worse at generalizing to new, unseen data. In other words, we risk developping a classifier that overfits.\n",
    "\n",
    "A simple method to guard against Type III errors is to use\n",
    "Cross-Validation. In **N-fold Cross-Validation**, we divide the data into N\n",
    "distinct chunks, or folds. Then, we repeat the experiment N times: each\n",
    "time holding out one of the folds for testing, training our classifier\n",
    "on the remaining N - 1 data folds, and reporting performance on the\n",
    "held-out fold. We can use different strategies for dividing the data:\n",
    "\n",
    "-   Consecutive splitting:\n",
    "  - cv000–cv099 = Split 1\n",
    "  - cv100–cv199 = Split 2\n",
    "  - etc.\n",
    "  \n",
    "-   Round-robin splitting (mod 10):\n",
    "  - cv000, cv010, cv020, … = Split 1\n",
    "  - cv001, cv011, cv021, … = Split 2\n",
    "  - etc.\n",
    "\n",
    "-   Random sampling/splitting\n",
    "  - Not used here (but you may choose to split this way in a non-educational situation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OeLcbSauGtR"
   },
   "source": [
    "#### (Q2.5) Write the code to implement 10-fold cross-validation using round-robin splitting for your Naive Bayes classifier from Q2.4 and compute the 10 accuracies. Report the final performance, which is the average of the performances per fold. If all splits perform equally well, this is a good sign. (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KeCGPa7Nuzx"
   },
   "outputs": [],
   "source": [
    "xp0, xp1, xp2, xp3, xp4, xp5, xp6, xp7, xp8, xp9 = [], [], [], [], [], [], [], [], [], []\n",
    "xn0, xn1, xn2, xn3, xn4, xn5, xn6, xn7, xn8, xn9 = [], [], [], [], [], [], [], [], [], []\n",
    "y0, y1, y2, y3, y4, y5, y6, y7, y8, y9 = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for i in range(len(reviews)):\n",
    "  for mod in range(10):\n",
    "    if (i - mod) % 10 == 0:\n",
    "      eval('y' + str(mod)).append(reviews[i])\n",
    "    else:\n",
    "      # Reviews until element 999 are negative, above positive\n",
    "      if i < 1000:\n",
    "        eval('xn' + str(mod)).append(reviews[i])\n",
    "      else:\n",
    "        eval('xp' + str(mod)).append(reviews[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrSb0LwoIVrC",
    "outputId": "be13f52e-4833-4ba2-f29d-e9282d46ddfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "  train_pos = eval('xp' + str(i))\n",
    "  train_neg = eval('xn' + str(i))\n",
    "  train_data = train_pos + train_neg\n",
    "  \n",
    "\n",
    "  train_words_pos = retrieve_words(train_pos)\n",
    "  train_words_neg = retrieve_words(train_neg)\n",
    "\n",
    "  count_pos = Counter(train_words_pos)\n",
    "  count_neg = Counter(train_words_neg)\n",
    "  total_pos = sum(count_pos.values())\n",
    "  total_neg = sum(count_neg.values())\n",
    "\n",
    "  unique_words = retrieve_unique_words(train_data)\n",
    "  prob = []\n",
    "\n",
    "  for rev in eval('y' + str(i)):\n",
    "    pr_pos = 0\n",
    "    pr_neg = 0\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "          pr_pos += np.log((count_pos[word[0].lower()] + 1) / (total_pos + len(unique_words)))\n",
    "          pr_neg += np.log((count_neg[word[0].lower()] + 1) / (total_neg + len(unique_words)))\n",
    "    prob.append(np.argmax([pr_neg,pr_pos]))\n",
    "\n",
    "  test_y = [label['sentiment'] for label in eval('y' + str(i))]\n",
    "  test_y_new = []\n",
    "\n",
    "  # Covert the sentiment result to 0 (negative) or 1 (positive)\n",
    "  for i in test_y:\n",
    "    if i == 'NEG':\n",
    "      test_y_new.append(0)\n",
    "    if i == 'POS':\n",
    "      test_y_new.append(1)\n",
    "\n",
    "  # Check if the review is correctly classified\n",
    "  result = []\n",
    "  for i in range(len(test_y_new)):\n",
    "    if test_y_new[i] == prob[i]:\n",
    "      result.append(1)\n",
    "    else:\n",
    "      result.append(0)\n",
    "\n",
    "  accuracy =sum(result) / len(result)\n",
    "  acc_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAWBfLPE2BE2",
    "outputId": "37cc13ff-8600-4b0b-f27d-d266d32f5c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79, 0.835, 0.81, 0.83, 0.775, 0.85, 0.83, 0.78, 0.825, 0.845]\n",
      "0.817\n"
     ]
    }
   ],
   "source": [
    "print('The accuracies for thhe different cycles:', acc_list)\n",
    "print('Mean accuracy =', np.mean(acc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otdlsDXBNyOa"
   },
   "source": [
    "#### (Q2.6) Report the variance of the 10 accuracy scores. (0.5pt)\n",
    "\n",
    "**Please report all future results using 10-fold cross-validation now\n",
    "(unless told to use the held-out test set).** Note: you're not allowed to use a library for computing the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZoBQm1KuNzNR",
    "outputId": "17e18753-d4cd-4ac9-e784-bb632b387a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006509999999999987\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "var = 1 / len(acc_list) * np.sum((np.array(acc_list) - np.mean(acc_list))**2)\n",
    "print(var)\n",
    "# The variance is very small. This indicates that the accuracy is similar\n",
    "# between the different cycles, which means that the way the data is splitted\n",
    "# doesn't have a big influence on the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6A2zX9_BRKm"
   },
   "source": [
    "## Features, overfitting, and the curse of dimensionality\n",
    "\n",
    "In the Bag-of-Words model, ideally we would like each distinct word in\n",
    "the text to be mapped to its own dimension in the output vector\n",
    "representation. However, real world text is messy, and we need to decide\n",
    "on what we consider to be a word. For example, is “`word`\" different\n",
    "from “`Word`\", from “`word`”, or from “`words`\"? Too strict a\n",
    "definition, and the number of features explodes, while our algorithm\n",
    "fails to learn anything generalisable. Too lax, and we risk destroying\n",
    "our learning signal. In the following section, you will learn about\n",
    "confronting the feature sparsity and the overfitting problems as they\n",
    "occur in NLP classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKK8FNt8VtcZ"
   },
   "source": [
    "### Stemming (1.5pts)\n",
    "\n",
    "To make your algorithm more robust, use stemming and hash different inflections of a word to the same feature in the BoW vector space. Please use the [Porter stemming\n",
    "    algorithm](http://www.nltk.org/howto/stem.html) from NLTK.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SrJ1BeLXTnk"
   },
   "source": [
    "#### (Q2.7): How does the performance of your classifier change when you use stemming on your training and test datasets? (1pt)\n",
    "Use cross-validation to evaluate the classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYqKBOiIrInT",
    "outputId": "bdcc3853-3142-42f6-c6da-6b2ca0399c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "acc_list2 = []\n",
    "\n",
    "# Perform cross validation over the dataset\n",
    "for i in range(10):\n",
    "\n",
    "  train_pos = eval('xp' + str(i))\n",
    "  train_neg = eval('xn' + str(i))\n",
    "  train_data = train_pos + train_neg\n",
    "  \n",
    "  # Stem both lists of words\n",
    "  train_words_pos = [stemmer.stem(w) for w in retrieve_words(train_pos)]\n",
    "  train_words_neg = [stemmer.stem(w) for w in retrieve_words(train_neg)]\n",
    "\n",
    "  count_pos = Counter(train_words_pos)\n",
    "  count_neg = Counter(train_words_neg)\n",
    "  total_pos = sum(count_pos.values())\n",
    "  total_neg = sum(count_neg.values())\n",
    "\n",
    "  unique_words = retrieve_unique_words(train_data)\n",
    "  prob = []\n",
    "\n",
    "  # Classify the reviews based on the occurences of the stemmed words\n",
    "  for rev in eval('y' + str(i)):\n",
    "    pr_pos = 0\n",
    "    pr_neg = 0\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "          word = stemmer.stem(word[0].lower())\n",
    "          pr_pos += np.log((count_pos[word] + 1) / (total_pos + len(unique_words)))\n",
    "          pr_neg += np.log((count_neg[word] + 1) / (total_neg + len(unique_words)))\n",
    "    prob.append(np.argmax([pr_neg,pr_pos]))\n",
    "\n",
    "  test_y = [label['sentiment'] for label in eval('y' + str(i))]\n",
    "  test_y_new = []\n",
    "\n",
    "  # Covert the sentiment result to 0 (negative) or 1 (positive)\n",
    "  for i in test_y:\n",
    "    if i == 'NEG':\n",
    "      test_y_new.append(0)\n",
    "    if i == 'POS':\n",
    "      test_y_new.append(1)\n",
    "\n",
    "  # Check if the review is correctly classified\n",
    "  result = []\n",
    "  for i in range(len(test_y_new)):\n",
    "    if test_y_new[i] == prob[i]:\n",
    "      result.append(1)\n",
    "    else:\n",
    "      result.append(0)\n",
    "\n",
    "  accuracy =sum(result) / len(result)\n",
    "  acc_list2.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjzhS-IJJyVX",
    "outputId": "626557e4-a497-4450-b4dd-cce7c45a9077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.785, 0.84, 0.81, 0.855, 0.77, 0.84, 0.825, 0.78, 0.825, 0.84]\n",
      "0.817\n"
     ]
    }
   ],
   "source": [
    "print('The accuracies for the different cycles:', acc_list2)\n",
    "print('Mean accuracy =', np.mean(acc_list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkDHVq_1XUVP"
   },
   "source": [
    "#### (Q2.8) What happens to the number of features (i.e., the size of the vocabulary) when using stemming as opposed to (Q2.4)? (0.5pt)\n",
    "Give actual numbers. You can use the held-out training set to determine these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MA3vee5-rJyy",
    "outputId": "38d1e98e-fb3e-4531-9c2a-90daa538638e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45348\n",
      "32404\n"
     ]
    }
   ],
   "source": [
    "# NOT USING STEMMING THEN VOCABULARY SIZE EQUAL TO TRAINING DATA\n",
    "\n",
    "# TRAINING DATA\n",
    "train_data1 = reviews[:900]\n",
    "test_data1 = reviews[900:1000]\n",
    "train_data2 = reviews[1000:1900]\n",
    "test_data2 = reviews[1900:]\n",
    "train_data = train_data1 + train_data2\n",
    "test_data = test_data1 + test_data2\n",
    "\n",
    "# Retrieve the unique word list for both the stemmed words an unstemmed words\n",
    "withoutstemming = retrieve_unique_words(train_data)\n",
    "withstemming = np.unique([stemmer.stem(w) for w in withoutstemming])\n",
    "\n",
    "print('Number of features without stemming =', len(withoutstemming))\n",
    "print('Number of features with stemming =', len(withstemming))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoazfxbNV5Lq"
   },
   "source": [
    "### N-grams (1.5pts)\n",
    "\n",
    "A simple way of retaining some of the word\n",
    "order information when using bag-of-words representations is to use **n-gram** features. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHjy3I7-qWiu"
   },
   "source": [
    "#### (Q2.9) Retrain your classifier from (Q2.4) using **unigrams+bigrams** and **unigrams+bigrams+trigrams** as features. (1pt)\n",
    "Report accuracy and compare it with that of the approaches you have previously implemented. You are allowed to use NLTK to build n-grams from sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eYuKMTOpq9jz"
   },
   "outputs": [],
   "source": [
    "train_neg = reviews[:900]\n",
    "test_neg = reviews[900:1000]\n",
    "train_pos = reviews[1000:1900]\n",
    "test_pos = reviews[1900:]\n",
    "train_data = train_neg + train_pos\n",
    "test_data = test_neg + test_pos\n",
    "\n",
    "# Find vocabulary size of the training data\n",
    "unique_words = retrieve_unique_words(train_data)\n",
    "voc_size = len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ctMzWP7RqGko"
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "train_words_pos = [w for w in retrieve_words(train_pos)]\n",
    "train_words_neg = [w for w in retrieve_words(train_neg)]\n",
    "\n",
    "all_bigrams_pos, all_bigrams_neg = [], []\n",
    "all_trigrams_pos, all_trigrams_neg = [], []\n",
    "\n",
    "for rev in train_pos:\n",
    "  for sentence in rev['content']:\n",
    "    sentence = np.array(sentence)\n",
    "    sentence = sentence[:,0]\n",
    "    bigrams_pos = list(ngrams(sentence, 2))\n",
    "    trigrams_pos = list(ngrams(sentence, 3))\n",
    "    for bigram in bigrams_pos:\n",
    "      all_bigrams_pos.append(bigram)\n",
    "    for trigram in trigrams_pos:\n",
    "      all_trigrams_pos.append(trigram)\n",
    "\n",
    "for rev in train_neg:\n",
    "  for sentence in rev['content']:\n",
    "    sentence = np.array(sentence)\n",
    "    sentence = sentence[:,0]\n",
    "    bigrams_neg = list(ngrams(sentence, 2))\n",
    "    trigrams_neg = list(ngrams(sentence, 3))\n",
    "    for bigram in bigrams_neg:\n",
    "      all_bigrams_neg.append(bigram)\n",
    "    for trigram in trigrams_neg:\n",
    "      all_trigrams_neg.append(trigram)\n",
    "\n",
    "# Create counters for unigrams\n",
    "count_pos_uni = Counter(train_words_pos)\n",
    "count_neg_uni = Counter(train_words_neg)\n",
    "total_pos_uni = sum(count_pos_uni.values())\n",
    "total_neg_uni = sum(count_neg_uni.values())\n",
    "\n",
    "# Create counters for bigrams\n",
    "count_pos_bi = Counter(all_bigrams_pos)\n",
    "count_neg_bi = Counter(all_bigrams_neg)\n",
    "total_pos_bi = sum(count_pos_bi.values())\n",
    "total_neg_bi = sum(count_neg_bi.values())\n",
    "\n",
    "# Create counters for trigrams\n",
    "count_pos_tri = Counter(all_trigrams_pos)\n",
    "count_neg_tri = Counter(all_trigrams_neg)\n",
    "total_pos_tri = sum(count_pos_tri.values())\n",
    "total_neg_tri = sum(count_neg_tri.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Pm0l208OqXpm"
   },
   "outputs": [],
   "source": [
    "def n_gram_classifier(test_data, trigram=False):\n",
    "  prob = []\n",
    "\n",
    "  for rev in test_data:\n",
    "    pr_pos = 0\n",
    "    pr_neg = 0\n",
    "    for sentence in rev['content']:\n",
    "      sentence = np.array(sentence)\n",
    "      sentence = sentence[:,0]\n",
    "      unigrams = list(ngrams(sentence, 1))    \n",
    "      bigrams = list(ngrams(sentence, 2))\n",
    "      trigrams = list(ngrams(sentence, 3))\n",
    "\n",
    "      for i in range(len(unigrams)):\n",
    "          pr_pos += np.log((count_pos_uni[unigrams[i]] + 1) / (total_pos_uni + len(unique_words)))\n",
    "          pr_neg += np.log((count_neg_uni[unigrams[i]] + 1) / (total_pos_uni + len(unique_words)))\n",
    "\n",
    "      for i in range(len(bigrams)):\n",
    "          pr_pos += np.log((count_pos_bi[bigrams[i]] + 1) / (count_pos_uni[bigrams[i][0]] + len(unique_words)))\n",
    "          pr_neg += np.log((count_neg_bi[bigrams[i]] + 1) / (count_neg_uni[bigrams[i][0]] + len(unique_words)))\n",
    "      if trigram == True:\n",
    "          for i in range(len(trigrams)):\n",
    "            pr_pos += np.log((count_pos_tri[trigrams[i]] + 1) / (count_pos_bi[trigrams[i][0:2]] + len(unique_words)))\n",
    "            pr_neg += np.log((count_neg_tri[trigrams[i]] + 1) / (count_neg_bi[trigrams[i][0:2]] + len(unique_words)))\n",
    "\n",
    "\n",
    "    prob.append(np.argmax([pr_neg,pr_pos]))\n",
    "\n",
    "  test_y = [label['sentiment'] for label in test_data]\n",
    "  test_y_new = []\n",
    "\n",
    "  # Convert pos/neg to 1/0\n",
    "  for i in test_y:\n",
    "    if i == 'NEG':\n",
    "      test_y_new.append(0)\n",
    "    if i == 'POS':\n",
    "      test_y_new.append(1)\n",
    "  sum(test_y_new)\n",
    "\n",
    "  result = []\n",
    "  for i in range(len(test_y_new)):\n",
    "    if test_y_new[i] == prob[i]:\n",
    "      result.append(1)\n",
    "    else:\n",
    "      result.append(0)\n",
    "\n",
    "  result = sum(result) / len(result)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4nROog2rErz",
    "outputId": "6a3fba5f-abb8-408c-8764-a5636637460f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for unigram + bigram\n",
      "Accuracy: 0.790\n"
     ]
    }
   ],
   "source": [
    "result = n_gram_classifier(test_data, trigram=False)\n",
    "\n",
    "print(\"Result for unigram + bigram\")\n",
    "print(\"Accuracy: %0.3f\" % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7GQj11TrTgf",
    "outputId": "6672586a-309c-436d-d308-ed893ab76de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for unigram + bigram\n",
      "Accuracy: 0.820\n"
     ]
    }
   ],
   "source": [
    "result2 = n_gram_classifier(test_data, trigram=True)\n",
    "\n",
    "print(\"Result for unigram + bigram\")\n",
    "print(\"Accuracy: %0.3f\" % result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "eBQ_qs3yqYYo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVrGGArkrWoL"
   },
   "source": [
    "\n",
    "#### Q2.10: How many features does the BoW model have to take into account now? (0.5pt)\n",
    "How would you expect the number of features to increase theoretically (e.g., linear, square, cubed, exponential)? How does this number compare, in practice, to the number of features at (Q2.8)?\n",
    "\n",
    "Use the held-out training set once again for this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEGZ9SV8pPaa"
   },
   "source": [
    "The vocabulary size of unigrams + bigrams = 532865\n",
    "The vocabulary size of unigrams + bigrams + trigrams = 1519211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_z8sAJeUrdtM",
    "outputId": "4c55d805-0422-43d4-8ba1-327dcf68b2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532865\n",
      "1519211\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "all_words, all_bigrams, all_trigrams = [], [], []\n",
    "\n",
    "for rev in reviews:\n",
    "  for sentence in rev['content']:\n",
    "    sentence = np.array(sentence)\n",
    "    sentence = sentence[:,0]\n",
    "    bigrams = list(ngrams(sentence, 2))\n",
    "    trigrams = list(ngrams(sentence, 3))\n",
    "    for word in sentence:\n",
    "      all_words.append(word)\n",
    "    for bigram in bigrams:\n",
    "      all_bigrams.append(bigram)\n",
    "    for trigram in trigrams:\n",
    "      all_trigrams.append(trigram)\n",
    "\n",
    "tot = len(set(all_words))\n",
    "tot2 = len(set(all_bigrams))\n",
    "tot3 = len(set(all_trigrams))\n",
    "\n",
    "print(tot + tot2)\n",
    "print(tot + tot2 + tot3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHWKDL3YV6vh"
   },
   "source": [
    "# (3) Support Vector Machines (4pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJSYhcVaoJGt"
   },
   "source": [
    "Though simple to understand, implement, and debug, one\n",
    "major problem with the Naive Bayes classifier is that its performance\n",
    "deteriorates (becomes skewed) when it is being used with features which\n",
    "are not independent (i.e., are correlated). Another popular classifier\n",
    "that doesn’t scale as well to big data, and is not as simple to debug as\n",
    "Naive Bayes, but that doesn’t assume feature independence is the Support\n",
    "Vector Machine (SVM) classifier.\n",
    "\n",
    "You can find more details about SVMs in Chapter 7 of Bishop: Pattern Recognition and Machine Learning.\n",
    "Other sources for learning SVM:\n",
    "* http://web.mit.edu/zoya/www/SVM.pdf\n",
    "* http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf\n",
    "* https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Use the scikit-learn implementation of \n",
    "[SVM](http://scikit-learn.org/stable/modules/svm.html) with the default parameters. (You are not expected to perform any hyperparameter tuning, but feel free to do it if you think it gives you good insights for the discussion in question 5.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LnzNtQBV8gr"
   },
   "source": [
    "#### (Q3.1): Train SVM and compare to Naive Bayes (2pts)\n",
    "\n",
    "Train an SVM classifier (sklearn.svm.LinearSVC) using the features collected for Naive Bayes. Compare the\n",
    "classification performance of the SVM classifier to that of the Naive\n",
    "Bayes classifier with smoothing.\n",
    "Use cross-validation to evaluate the performance of the classifiers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqcwkHOEVky6"
   },
   "outputs": [],
   "source": [
    "words_total = [w for w in retrieve_words(reviews)]\n",
    "count_total = Counter(words_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zAfkpjsY6WU"
   },
   "outputs": [],
   "source": [
    "xp0, xp1, xp2, xp3, xp4, xp5, xp6, xp7, xp8, xp9 = [], [], [], [], [], [], [], [], [], []\n",
    "xn0, xn1, xn2, xn3, xn4, xn5, xn6, xn7, xn8, xn9 = [], [], [], [], [], [], [], [], [], []\n",
    "y0, y1, y2, y3, y4, y5, y6, y7, y8, y9 = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for i in range(len(reviews)):\n",
    "  for mod in range(10):\n",
    "    if (i - mod) % 10 == 0:\n",
    "      eval('y' + str(mod)).append(reviews[i])\n",
    "    else:\n",
    "      # Reviews until element 999 are negative, above positive\n",
    "      if i < 1000:\n",
    "        eval('xn' + str(mod)).append(reviews[i])\n",
    "      else:\n",
    "        eval('xp' + str(mod)).append(reviews[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBscui8Mvoz0",
    "outputId": "d913ae78-e504-4ce2-f4b8-f0dd1e616093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "acc_list = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "  print(i)\n",
    "\n",
    "  train_pos = eval('xp' + str(i))\n",
    "  train_neg = eval('xn' + str(i))\n",
    "  train_data = train_pos + train_neg\n",
    "\n",
    "  x_values = []\n",
    "  for rev in train_data:\n",
    "    # SET EVERYTHING BACK TO 0\n",
    "    count_total = dict.fromkeys(count_total, 0)\n",
    "    # COUNT WORDS IN REVIEW\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        count_total[word[0].lower()] += 1\n",
    "    x_values.append(list(count_total.values()))\n",
    "\n",
    "  X = x_values\n",
    "  y = [label['sentiment'] for label in train_data]\n",
    "  train_y_new = []\n",
    "  for p in y:\n",
    "    if p == 'NEG':\n",
    "      train_y_new.append(0)\n",
    "    if p == 'POS':\n",
    "      train_y_new.append(1)\n",
    "  clf = svm.SVC(kernel = 'linear')\n",
    "  clf.fit(X, train_y_new) \n",
    "\n",
    "  #COUNT TEST DATA\n",
    "  x_test_values = []\n",
    "  for rev in eval('y' + str(i)):\n",
    "    count_total = dict.fromkeys(count_total, 0)\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        count_total[word[0].lower()] += 1\n",
    "    x_test_values.append(list(count_total.values()))\n",
    "\n",
    "  y_predict = clf.predict(x_test_values)   \n",
    "\n",
    "  test_y = [label['sentiment'] for label in eval('y' + str(i))]\n",
    "  test_y_new = []\n",
    "\n",
    "  for i in test_y:\n",
    "    if i == 'NEG':\n",
    "      test_y_new.append(0)\n",
    "    if i == 'POS':\n",
    "      test_y_new.append(1)\n",
    "\n",
    "  result = []\n",
    "  for i in range(len(test_y_new)):\n",
    "    if test_y_new[i] == y_predict[i]:\n",
    "      result.append(1)\n",
    "    else:\n",
    "      result.append(0)\n",
    "\n",
    "  accuracy =sum(result) / len(result)\n",
    "  acc_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-h2ekaL9hOuh",
    "outputId": "e1fd1c16-6213-4d07-bec3-69a6f59a284e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.837"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(acc_list)\n",
    "print(np.mean(acc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifXVWcK0V9qY"
   },
   "source": [
    "### POS disambiguation (2pts)\n",
    "\n",
    "Now add in part-of-speech features. You will find the\n",
    "movie review dataset has already been POS-tagged for you ([here](https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf) you find the tagset). Try to\n",
    "replicate the results obtained by Pang et al. (2002).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA3I82o4oWGu"
   },
   "source": [
    "####(Q3.2) Replace your features with word+POS features, and report performance with the SVM. Use cross-validation to evaluate the classifier and compare the results with (Q3.1). Does part-of-speech information help? Explain why this may be the case. (1pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOvjYe-t2Br6"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def retrieve_words_POS(data):\n",
    "  words = []\n",
    "  for rev in data:\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        word1 = word[0].lower()\n",
    "        words.append(word1+word[1])\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1O26xRdoVN_"
   },
   "outputs": [],
   "source": [
    "words_total = [w for w in retrieve_words_POS(reviews)]\n",
    "count_total = Counter(words_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mel0nzFwpeGP",
    "outputId": "f824c60c-2b69-4d6a-f259-4dc325b72bb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "acc_list = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "  print(i)\n",
    "\n",
    "  train_pos = eval('xp' + str(i))\n",
    "  train_neg = eval('xn' + str(i))\n",
    "  train_data = train_pos + train_neg\n",
    "\n",
    "  x_values = []\n",
    "  for rev in train_data:\n",
    "    # SET EVERYTHING BACK TO 0\n",
    "    count_total = dict.fromkeys(count_total, 0)\n",
    "    # COUNT WORDS IN REVIEW\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        word1 = word[0].lower()\n",
    "        combi = word1+word[1]\n",
    "        count_total[combi] += 1\n",
    "    x_values.append(list(count_total.values()))\n",
    "\n",
    "  X = x_values\n",
    "  y = [label['sentiment'] for label in train_data]\n",
    "  train_y_new = []\n",
    "  for p in y:\n",
    "    if p == 'NEG':\n",
    "      train_y_new.append(0)\n",
    "    if p == 'POS':\n",
    "      train_y_new.append(1)\n",
    "  clf = svm.SVC(kernel = 'linear')\n",
    "  clf.fit(X, train_y_new) \n",
    "\n",
    "  #COUNT TEST DATA\n",
    "  x_test_values = []\n",
    "  for rev in eval('y' + str(i)):\n",
    "    count_total = dict.fromkeys(count_total, 0)\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        word1 = word[0].lower()\n",
    "        combi = word1+word[1]\n",
    "        count_total[combi] += 1\n",
    "    x_test_values.append(list(count_total.values()))\n",
    "\n",
    "  y_predict = clf.predict(x_test_values)   \n",
    "\n",
    "  test_y = [label['sentiment'] for label in eval('y' + str(i))]\n",
    "  test_y_new = []\n",
    "\n",
    "  for i in test_y:\n",
    "    if i == 'NEG':\n",
    "      test_y_new.append(0)\n",
    "    if i == 'POS':\n",
    "      test_y_new.append(1)\n",
    "\n",
    "  result = []\n",
    "  for i in range(len(test_y_new)):\n",
    "    if test_y_new[i] == y_predict[i]:\n",
    "      result.append(1)\n",
    "    else:\n",
    "      result.append(0)\n",
    "\n",
    "  accuracy =sum(result) / len(result)\n",
    "  acc_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFvVf95ewRMc",
    "outputId": "eda251eb-87b5-4a2f-bb31-475bd8906701"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380000000000001"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list\n",
    "np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0dt_oQupUNe"
   },
   "source": [
    "POS Tagging does not result in a higher accuracy of the classification process. This makes sense because a POS tag is neutral, it gives grammatical information about a word, and not semantical. Because most words which contains sentiments are adjectives it doesn't give that much more information. For example the words 'bad' and 'good' get the same tag while they actually indicate an opposite sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su-3w87eMW0w"
   },
   "source": [
    "#### (Q3.3) Discard all closed-class words from your data (keep only nouns, verbs, adjectives, and adverbs), and report performance. Does this help? Use cross-validation to evaluate the classifier and compare the results with (Q3.2). Are closed-class words detrimental to the classifier? Explain why this may be the case. (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCUPlPozCYUX"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def retrieve_words_POS_CC(data):\n",
    "  keepers = ['JJ', 'JJR' , 'JJS' , 'RB' , 'RBR', 'RBS', 'NN','NNS','NNPS' , 'VB', 'VBD', 'VBG', 'VBN','VBP','VBZ']\n",
    "  words = []\n",
    "  for rev in data:\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        word1 = word[0].lower()\n",
    "        if word[1] in keepers:\n",
    "          words.append(word1+word[1])\n",
    "  return words\n",
    "\n",
    "words_total = [w for w in retrieve_words_POS_CC(reviews)]\n",
    "count_total = Counter(words_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9yQro4D_JzX",
    "outputId": "1b5ff23f-8114-43a8-b86a-0e32aa877f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "acc_list = []\n",
    "keepers = ['JJ', 'JJR' , 'JJS' , 'RB' , 'RBR', 'RBS', 'NN','NNS','NNPS' , 'VB', 'VBD', 'VBG', 'VBN','VBP','VBZ']\n",
    "for i in range(10):\n",
    "\n",
    "  print(i)\n",
    "\n",
    "  train_pos = eval('xp' + str(i))\n",
    "  train_neg = eval('xn' + str(i))\n",
    "  train_data = train_pos + train_neg\n",
    "\n",
    "  x_values = []\n",
    "  for rev in train_data:\n",
    "    # SET EVERYTHING BACK TO 0\n",
    "    count_total = dict.fromkeys(count_total, 0)\n",
    "    # COUNT WORDS IN REVIEW\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        word1 = word[0].lower()\n",
    "        if word[1] in keepers:\n",
    "          combi = word1+word[1]\n",
    "          count_total[combi] += 1\n",
    "    x_values.append(list(count_total.values()))\n",
    "\n",
    "  X = x_values\n",
    "  y = [label['sentiment'] for label in train_data]\n",
    "  train_y_new = []\n",
    "  for p in y:\n",
    "    if p == 'NEG':\n",
    "      train_y_new.append(0)\n",
    "    if p == 'POS':\n",
    "      train_y_new.append(1)\n",
    "  clf = svm.SVC(kernel = 'linear')\n",
    "  clf.fit(X, train_y_new) \n",
    "\n",
    "  #COUNT TEST DATA\n",
    "  x_test_values = []\n",
    "  for rev in eval('y' + str(i)):\n",
    "    count_total = dict.fromkeys(count_total, 0)\n",
    "    for sentence in rev['content']:\n",
    "      for word in sentence:\n",
    "        word1 = word[0].lower()\n",
    "        if word[1] in keepers:\n",
    "          combi = word1+word[1]\n",
    "          count_total[combi] += 1\n",
    "    x_test_values.append(list(count_total.values()))\n",
    "\n",
    "  y_predict = clf.predict(x_test_values)   \n",
    "\n",
    "  test_y = [label['sentiment'] for label in eval('y' + str(i))]\n",
    "  test_y_new = []\n",
    "\n",
    "  for i in test_y:\n",
    "    if i == 'NEG':\n",
    "      test_y_new.append(0)\n",
    "    if i == 'POS':\n",
    "      test_y_new.append(1)\n",
    "\n",
    "  result = []\n",
    "  for i in range(len(test_y_new)):\n",
    "    if test_y_new[i] == y_predict[i]:\n",
    "      result.append(1)\n",
    "    else:\n",
    "      result.append(0)\n",
    "\n",
    "  accuracy =sum(result) / len(result)\n",
    "  acc_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kgct-UvaG00K",
    "outputId": "8f279c81-ce65-40ae-90aa-5570c557135f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400000000000002"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list\n",
    "np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaxCVrs8pWSp"
   },
   "source": [
    "The accuracy without closed-class words is similar. This means that closed-class words are not detrimental to the classifier. The reason for this could be that closed class words are observed in a similar amount in the positive reviews as in the negative results, which means that the influence on the classification process is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfwqOciAl2No"
   },
   "source": [
    "# (Q4) Discussion (max. 500 words). (5pts)\n",
    "\n",
    "> Based on your experiments, what are the effective features and techniques in sentiment analysis? What information do different features encode?\n",
    "Why is this important? What are the limitations of these features and techniques?\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYuse5WLmekZ"
   },
   "source": [
    "Multiple techniques are being used to train a classifier to be able to classify movie reviews.\n",
    "\n",
    "Setting a threshold for the amount of positive words in comparison with the amount of negative words does work but relatively bad, it gives an accuracy of 69%. One approach of trying to achieve a higher accuracy is setting a threshold which adjusts to the document length. With a different document the length, the average distance between the amount of positive and negative words will change. Adjusting for this fact does not improve the accuracy.\n",
    "\n",
    "An effective technique is the Naive bayes classifier, it gives an accuracy of 82,5%. This feature provides information about how often words are observed in a positive document compared to a negative document.The classification system is adjusted to the relative appearances of positive/negative documents.\n",
    "\n",
    "For obtaining a more accurate accuracy cross-validation is applied for different techniques. In this case 10 different training and test cycles were performed. With the average accuracy of the classification process a more robust judgement can be made about how well the classifier is able to classify the data. In the case of the naïve bayes all the cycles gave a similar accuracy, with a mean accuracy of 0.817.\n",
    "\n",
    "Smoothing is a method to take unseen words into account for the classification process. A minimal possibility of one divided by the vocabulary size. In this case it does not significantly improve the accuracy\n",
    "\n",
    "Stemming is a technique to convert all the words to their stem. In this case it doesn't influence the accuracy. The reason for this is probably that the stem of a positive word containing a specific sentiment probably contains the same sentiment, so stemming the words does not influence the classification process that much. Although the accuracy doesn’t change that much, it is a more robust way of classifying since less different words are being evaluated and the data will be more uncluttered.\n",
    "\n",
    "N-grams can be used to take the history into account. bigrams can be used to find the probability of a word to follow a specific word. Trigrams can be used to find the probability of a word following two specific consecutive words. the accuracy when using unigrams and bigram is 79%, for unigrams, bigrams and trigrams the accuracy is 82%.\n",
    "\n",
    "Using a SVM classifier slightly improves the accuracy. This method tries to fit a line through the data based on the words in the review with the corresponding label, such that the data can be separated as good as possible.\n",
    "\n",
    "POS Tagging before the classification process gives the same accuracy when classifying with SVM. The reason for this is probably that a POS tag is very neutral. It gives information about the grammar, but not about the sentiment. Most sentiment words are adjectives which can both be positive or negative, while they obtain the same POS tag. Dropping words with specific tags that will surely not contain a sentiment also doesn’t increase the accuracy significantly. This can be due to the prevalence of sentiment words in the classification process. When they account way more for the classification, dropping the other words does not change that much.\n",
    "\n",
    "The best accuracy is obtained by training a SVM classifier, which slightly improves when dropping in significant POS classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwaKwfWQhRk_"
   },
   "source": [
    "# Submission \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOUeaET5ijk-"
   },
   "outputs": [],
   "source": [
    "# Write your names and student numbers here:\n",
    "# Denny Smit  #11296925  \n",
    "# Boaz Beukers #12188239"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3A9K-H6Tii3X"
   },
   "source": [
    "**That's it!**\n",
    "\n",
    "- Check if you answered all questions fully and correctly. \n",
    "- Download your completed notebook using `File -> Download .ipynb` \n",
    "- Check if your answers are all included in the file you submit.\n",
    "- Submit your .ipynb file via *Canvas*. One submission per group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHslatYAKBrF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
